# comment_spam.py

import pandas as pd
import re
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
import joblib

def preprocess_text(text):
    """
    Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n: chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng, lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát v√† kho·∫£ng tr·∫Øng th·ª´a.
    """
    text = text.lower()
    # Lo·∫°i b·ªè k√Ω t·ª± kh√¥ng ph·∫£i ch·ªØ, s·ªë ho·∫∑c kho·∫£ng tr·∫Øng
    text = re.sub(r'[^a-z0-9\s]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def main():
    # ƒê∆∞·ªùng d·∫´n t·ªõi file comment spam CSV
    comment_file = '/Users/ManhAT18A/Desktop/ML/data/comment_spam.csv'
    df_comment = pd.read_csv(comment_file)
    print("Comment Spam Dataset Columns:", df_comment.columns.tolist())
    
    # X√¢y d·ª±ng DataFrame v·ªõi 2 c·ªôt: text (n·ªôi dung) v√† label (spam ho·∫∑c ham)
    # Gi·∫£ s·ª≠: CLASS = 1 l√† spam, c√°c gi√° tr·ªã kh√°c l√† ham
    df = pd.DataFrame({
        'text': df_comment['CONTENT'],
        'label': df_comment['CLASS'].apply(lambda x: 'spam' if x == 1 else 'ham')
    })
    
    # Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n
    df['text_clean'] = df['text'].apply(preprocess_text)
    print("Sample processed text:\n", df[['text', 'text_clean', 'label']].head())
    
    # Chu·∫©n b·ªã d·ªØ li·ªáu hu·∫•n luy·ªán
    X = df['text_clean']
    y = df['label']
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # Vector h√≥a vƒÉn b·∫£n s·ª≠ d·ª•ng TF-IDF
    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)
    X_train_vec = vectorizer.fit_transform(X_train)
    X_test_vec = vectorizer.transform(X_test)
    
    # Hu·∫•n luy·ªán m√¥ h√¨nh Logistic Regression
    model = LogisticRegression(max_iter=1000)
    model.fit(X_train_vec, y_train)
    
    # ƒê√°nh gi√° m√¥ h√¨nh
    y_pred = model.predict(X_test_vec)
    print("Confusion Matrix:")
    print(confusion_matrix(y_test, y_pred))
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))
    
    # L∆∞u m√¥ h√¨nh v√† vectorizer
    joblib.dump(model, 'comment_spam_model.pkl')
    joblib.dump(vectorizer, 'comment_tfidf_vectorizer.pkl')
    print("Comment spam model and vectorizer saved.")

if __name__ == '__main__':
    main()

# ------------------------------------------------------------------------------------

# import pandas as pd
# import re
# import joblib
# from sklearn.model_selection import train_test_split
# from sklearn.feature_extraction.text import TfidfVectorizer
# from sklearn.linear_model import LogisticRegression
# from sklearn.naive_bayes import MultinomialNB
# from sklearn.svm import SVC
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.metrics import classification_report, confusion_matrix

# def preprocess_text(text):
#     """
#     Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n: chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng, lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát v√† kho·∫£ng tr·∫Øng th·ª´a.
#     """
#     text = text.lower()
#     text = re.sub(r'[^a-z0-9\s]', '', text)
#     text = re.sub(r'\s+', ' ', text).strip()
#     return text

# def main():
#     # ƒê∆∞·ªùng d·∫´n t·ªõi file comment spam CSV
#     comment_file = '/Users/ManhAT18A/Desktop/ML/data/comment_spam.csv'
#     df_comment = pd.read_csv(comment_file)
#     print("Comment Spam Dataset Columns:", df_comment.columns.tolist())
    
#     # X√¢y d·ª±ng DataFrame v·ªõi 2 c·ªôt: text (n·ªôi dung) v√† label (spam ho·∫∑c ham)
#     df = pd.DataFrame({
#         'text': df_comment['CONTENT'],
#         'label': df_comment['CLASS'].apply(lambda x: 'spam' if x == 1 else 'ham')
#     })
    
#     # Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n
#     df['text_clean'] = df['text'].apply(preprocess_text)
#     print("Sample processed text:\n", df[['text', 'text_clean', 'label']].head())
    
#     # Chu·∫©n b·ªã d·ªØ li·ªáu hu·∫•n luy·ªán
#     X = df['text_clean']
#     y = df['label']
    
#     X_train, X_test, y_train, y_test = train_test_split(
#         X, y, test_size=0.2, random_state=42, stratify=y
#     )
    
#     # Vector h√≥a vƒÉn b·∫£n s·ª≠ d·ª•ng TF-IDF
#     vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)
#     X_train_vec = vectorizer.fit_transform(X_train)
#     X_test_vec = vectorizer.transform(X_test)
    
#     # Danh s√°ch c√°c m√¥ h√¨nh
#     models = {
#         'Logistic Regression': LogisticRegression(max_iter=1000),
#         'Naive Bayes': MultinomialNB(),
#         'SVM': SVC(kernel='linear', probability=True),
#         'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)
#     }
    
#     # Hu·∫•n luy·ªán, ƒë√°nh gi√° v√† l∆∞u t·ª´ng m√¥ h√¨nh
#     for name, model in models.items():
#         print(f"\nüîπ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh: {name}")
#         model.fit(X_train_vec, y_train)
#         y_pred = model.predict(X_test_vec)
        
#         print("Confusion Matrix:")
#         print(confusion_matrix(y_test, y_pred))
#         print("\nClassification Report:")
#         print(classification_report(y_test, y_pred))
        
#         # L∆∞u m√¥ h√¨nh
#         model_filename = f'{name.replace(" ", "_").lower()}_model.pkl'
#         joblib.dump(model, model_filename)
#         print(f"‚úÖ ƒê√£ l∆∞u {name} v√†o {model_filename}")
    
#     # L∆∞u vectorizer
#     joblib.dump(vectorizer, 'comment_tfidf_vectorizer.pkl')
#     print("‚úÖ ƒê√£ l∆∞u TF-IDF vectorizer.")
    
#     # ƒê√°nh gi√° chung
#     print("\nüîç Nh·∫≠n x√©t t·ª´ng m√¥ h√¨nh:")
#     print("- Logistic Regression: ƒê∆°n gi·∫£n, hi·ªáu qu·∫£ v·ªõi d·ªØ li·ªáu nh·ªè, nhanh ch√≥ng.")
#     print("- Naive Bayes: T·ªët cho x·ª≠ l√Ω vƒÉn b·∫£n, nh∆∞ng gi·∫£ ƒë·ªãnh ƒë·ªôc l·∫≠p ƒëi·ªÅu ki·ªán c√≥ th·ªÉ kh√¥ng ch√≠nh x√°c.")
#     print("- SVM: M·∫°nh m·∫Ω, nh∆∞ng ch·∫≠m v·ªõi t·∫≠p d·ªØ li·ªáu l·ªõn.")
#     print("- Random Forest: T·ªët cho d·ªØ li·ªáu ph·ª©c t·∫°p, nh∆∞ng ti√™u t·ªën t√†i nguy√™n h∆°n.")

# if __name__ == '__main__':
#     main()


# ------------------------------------------------------------------------------------


# import pandas as pd
# import re
# import joblib
# import matplotlib.pyplot as plt
# import seaborn as sns
# from sklearn.model_selection import train_test_split
# from sklearn.feature_extraction.text import TfidfVectorizer
# from sklearn.linear_model import LogisticRegression
# from sklearn.naive_bayes import MultinomialNB
# from sklearn.svm import SVC
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.metrics import classification_report, accuracy_score

# def preprocess_text(text):
#     """Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n"""
#     text = text.lower()
#     text = re.sub(r'[^a-z0-9\s]', '', text)
#     text = re.sub(r'\s+', ' ', text).strip()
#     return text

# def train_and_evaluate(models, X_train_vec, X_test_vec, y_train, y_test):
#     """Hu·∫•n luy·ªán v√† ƒë√°nh gi√° nhi·ªÅu m√¥ h√¨nh"""
#     results = []
    
#     for name, model in models.items():
#         print(f"üîπ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh: {name}")
#         model.fit(X_train_vec, y_train)
#         y_pred = model.predict(X_test_vec)
        
#         acc = accuracy_score(y_test, y_pred)
#         report = classification_report(y_test, y_pred, output_dict=True)
        
#         print(f"üìä ƒê√°nh gi√° {name}:\n", classification_report(y_test, y_pred))
        
#         # L∆∞u model
#         joblib.dump(model, f'{name.lower().replace(" ", "_")}_model.pkl')
        
#         # Ghi nh·∫≠n k·∫øt qu·∫£
#         results.append({
#             'Model': name,
#             'Accuracy': acc,
#             'Precision (Spam)': report['spam']['precision'],
#             'Recall (Spam)': report['spam']['recall'],
#             'F1-score (Spam)': report['spam']['f1-score'],
#         })
    
#     return pd.DataFrame(results)

# def plot_results(results_df):
#     """V·∫Ω bi·ªÉu ƒë·ªì so s√°nh m√¥ h√¨nh"""
#     plt.figure(figsize=(10, 5))
#     sns.barplot(x='Model', y='Accuracy', data=results_df, palette='viridis')
#     plt.title('So s√°nh Accuracy gi·ªØa c√°c m√¥ h√¨nh')
#     plt.ylabel('Accuracy')
#     plt.ylim(0, 1)
#     plt.xticks(rotation=20)
#     plt.show()

#     plt.figure(figsize=(10, 5))
#     results_df.set_index('Model')[['Precision (Spam)', 'Recall (Spam)', 'F1-score (Spam)']].plot(kind='bar')
#     plt.title('So s√°nh Precision, Recall, F1-score gi·ªØa c√°c m√¥ h√¨nh')
#     plt.ylabel('Score')
#     plt.ylim(0, 1)
#     plt.xticks(rotation=20)
#     plt.legend(loc='lower right')
#     plt.show()

# def main():
#     comment_file = '/Users/ManhAT18A/Desktop/ML/data/comment_spam.csv'
#     df_comment = pd.read_csv(comment_file)
    
#     df = pd.DataFrame({
#         'text': df_comment['CONTENT'],
#         'label': df_comment['CLASS'].apply(lambda x: 'spam' if x == 1 else 'ham')
#     })
    
#     df['text_clean'] = df['text'].apply(preprocess_text)

#     X = df['text_clean']
#     y = df['label']

#     X_train, X_test, y_train, y_test = train_test_split(
#         X, y, test_size=0.2, random_state=42, stratify=y
#     )

#     vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)
#     X_train_vec = vectorizer.fit_transform(X_train)
#     X_test_vec = vectorizer.transform(X_test)
    
#     # L∆∞u vectorizer
#     joblib.dump(vectorizer, 'comment_tfidf_vectorizer.pkl')

#     models = {
#         'Logistic Regression': LogisticRegression(max_iter=1000),
#         'Naive Bayes': MultinomialNB(),
#         'SVM': SVC(kernel='linear'),
#         'Random Forest': RandomForestClassifier(n_estimators=100),
#     }
    
#     results_df = train_and_evaluate(models, X_train_vec, X_test_vec, y_train, y_test)
    
#     print("\nüìå B·∫£ng so s√°nh m√¥ h√¨nh:")
#     print(results_df)
    
#     # V·∫Ω bi·ªÉu ƒë·ªì
#     plot_results(results_df)

# if __name__ == '__main__':
#     main()
